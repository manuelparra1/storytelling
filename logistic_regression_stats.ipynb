{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "193b8697",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fe7c81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_telco_data():\n",
    "    '''\n",
    "\n",
    "    checks if 'telco.csv' exists\n",
    "    if it does it will load file with Pandas\n",
    "\n",
    "    otherwise, it will connect to SQL server\n",
    "    using get_db_url('telco_churn') from env.py\n",
    "    and read_sql() from Pandas\n",
    "\n",
    "    returns a dataframe\n",
    "\n",
    "    '''\n",
    "    path = 'telco.csv'\n",
    "    file_exists = os.path.exists(path)\n",
    "    if file_exists:\n",
    "\n",
    "        df = pd.read_csv(path)\n",
    "\n",
    "        return df\n",
    "\n",
    "    else:\n",
    "        url = env.get_db_url('telco_churn')\n",
    "        sql_query = '''\n",
    "                        SELECT\n",
    "                            *\n",
    "                        FROM\n",
    "                            customers AS c\n",
    "                            LEFT JOIN internet_service_types AS ist USING (internet_service_type_id)\n",
    "                            LEFT JOIN customer_subscriptions AS csb USING (customer_id)\n",
    "                            LEFT JOIN payment_types AS pt USING (payment_type_id)\n",
    "                            LEFT JOIN contract_types AS ct USING (contract_type_id)\n",
    "                            LEFT JOIN customer_churn AS ccr USING (customer_id)\n",
    "                            LEFT JOIN customer_contracts AS ccn USING (customer_id)\n",
    "                            LEFT JOIN customer_details AS cd USING (customer_id)\n",
    "                            LEFT JOIN customer_payments AS cp USING (customer_id)\n",
    "                            LEFT JOIN customer_signups AS cs USING (customer_id);\n",
    "                    '''\n",
    "        df = pd.read_sql(sql_query, url)\n",
    "        df.to_csv('telco_churn.csv')\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06fb0117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_telco_data(df):\n",
    "    import pandas as pd\n",
    "    \n",
    "    df = df.loc[:,~df.columns.duplicated()].copy()\n",
    "    df['total_charges'] = (df.total_charges + '0').astype('float')\n",
    "    df = df.drop(columns=['internet_service_type_id', 'contract_type_id', 'payment_type_id'])\n",
    "    df['gender_encoded'] = df.gender.map({'Female': 1, 'Male': 0})\n",
    "    df['partner_encoded'] = df.partner.map({'Yes': 1, 'No': 0})\n",
    "    df['dependents_encoded'] = df.dependents.map({'Yes': 1, 'No': 0})\n",
    "    df['phone_service_encoded'] = df.phone_service.map({'Yes': 1, 'No': 0})\n",
    "    df['paperless_billing_encoded'] = df.paperless_billing.map({'Yes': 1, 'No': 0})\n",
    "    df['churn_encoded'] = df.churn.map({'Yes': 1, 'No': 0})\n",
    "    dummy_df = pd.get_dummies(df[['multiple_lines', \\\n",
    "                              'online_security', \\\n",
    "                              'online_backup', \\\n",
    "                              'device_protection', \\\n",
    "                              'tech_support', \\\n",
    "                              'streaming_tv', \\\n",
    "                              'streaming_movies', \\\n",
    "                              'contract_type', \\\n",
    "                              'internet_service_type', \\\n",
    "                              'payment_type'\n",
    "                            ]],\n",
    "                              drop_first=True)\n",
    "    df = pd.concat( [df, dummy_df], axis=1 )\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1d530bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_telco_data(df, target='churn'):\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    '''\n",
    "    split_data will take in a single pandas dataframe\n",
    "    it will split it into a train, validate, and test set\n",
    "    and it will return three values:\n",
    "    train, val, test (in this order) -- all pandas Dataframes\n",
    "    '''\n",
    "    train, test = train_test_split(df, \n",
    "                               train_size = 0.8,\n",
    "                               random_state=1349,\n",
    "                              stratify=df[target])\n",
    "    train, val = train_test_split(train,\n",
    "                             train_size = 0.8,\n",
    "                             random_state=1349,\n",
    "                             stratify=train[target])\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a88e7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_telco_data(df,target='churn_encoded'):\n",
    "    columns_to_drop = ['customer_id','gender','partner','dependents','phone_service','paperless_billing','churn',\\\n",
    "              'multiple_lines', 'online_security', 'online_backup', 'device_protection', 'tech_support',\\\n",
    "               'streaming_tv', 'streaming_movies', 'contract_type', 'internet_service_type', 'payment_type',\\\n",
    "                  'contract_type','churn_month','signup_date']\n",
    "    columns_to_drop.append(target)\n",
    "    \n",
    "    X_df = df.drop(columns=columns_to_drop)\n",
    "    y_df = df[target]\n",
    "\n",
    "    return X_df, y_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf686f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acquiring, cleaning, and adding features to data\n",
    "df = get_telco_data()\n",
    "df = clean_telco_data(df)\n",
    "\n",
    "# splitting data into train, validate, and test\n",
    "train, validate, test = split_telco_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e97478c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving unique customer id for later in the correct order to match predictions in CSV\n",
    "train_cust, validate_cust, test_cust = train['customer_id'],validate['customer_id'],test['customer_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80a5b1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate Target Variable\n",
    "X_train, y_train = model_telco_data(train)\n",
    "X_validate, y_validate = model_telco_data(validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "131eb643",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = df['churn_encoded'].value_counts().idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adf346ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression accuracy: 33.41% on training set\n",
      "           Baseline accuracy: 73.46% on training set\n",
      "\n",
      "Logistic Regression accuracy: 33.36% on validate set\n",
      "           Baseline accuracy: 73.47% on validate set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logit = LogisticRegression(C=1, class_weight={0:1, 1:99}, random_state=123, intercept_scaling=1, solver='lbfgs')\n",
    "logit.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logit.predict(X_train)\n",
    "train_acc = pd.DataFrame()\n",
    "train_acc['train_prediction']=y_pred\n",
    "train_acc['actual']=y_train.tolist()\n",
    "train_acc['baseline_prediction']=baseline\n",
    "model_accuracy = (train_acc.train_prediction == train_acc.actual).mean()\n",
    "baseline_accuracy = (train_acc.baseline_prediction == train_acc.actual).mean()\n",
    "\n",
    "print(f'Logistic Regression accuracy: {model_accuracy:.2%} on training set')\n",
    "print(f'           Baseline accuracy: {baseline_accuracy:.2%} on training set\\n')\n",
    "\n",
    "\n",
    "y_pred = logit.predict(X_validate)\n",
    "validate_acc = pd.DataFrame()\n",
    "validate_acc['validate_prediction']=y_pred\n",
    "validate_acc['actual']=y_validate.tolist()\n",
    "validate_acc['baseline_prediction']=baseline\n",
    "model_accuracy = (validate_acc.validate_prediction == validate_acc.actual).mean()\n",
    "baseline_accuracy = (validate_acc.baseline_prediction == validate_acc.actual).mean()\n",
    "\n",
    "print(f'Logistic Regression accuracy: {model_accuracy:.2%} on validate set')\n",
    "print(f'           Baseline accuracy: {baseline_accuracy:.2%} on validate set\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
